{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matt's Machine Learning Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-mmmkTLKmxh"
      },
      "source": [
        "import sklearn\n",
        "from gensim.models import Word2Vec\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwaj5mfPu1rb"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwaFY7fShhT"
      },
      "source": [
        "# file path\n",
        "# find the dataset located online at https://osf.io/efrqt/\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/SigmaLaw-ABSA.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jRdfGaXDTUdd",
        "outputId": "bd246502-04a0-4db5-fe53-36c3877f3b78"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Party</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Overall Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Petitioner Jae Lee moved to the United States ...</td>\n",
              "      <td>[[Petitioner Jae Lee,his,he],[]]</td>\n",
              "      <td>[[0,0,0],[]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the 35 years he has spent in this country, ...</td>\n",
              "      <td>[[he_1,he_2,he_3],[]]</td>\n",
              "      <td>[[0,0,0],[]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the 35 years he has spent in this country, ...</td>\n",
              "      <td>[[he_1,he_2],[]]</td>\n",
              "      <td>[[0,0],[]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the 35 years he has spent in this country</td>\n",
              "      <td>[[he],[]]</td>\n",
              "      <td>[[0],[]]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In 2008, federal officials received a tip from...</td>\n",
              "      <td>[[lee],[federal officials]]</td>\n",
              "      <td>[[-1],[1]]</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  ... Overall Sentiment\n",
              "0  Petitioner Jae Lee moved to the United States ...  ...                 0\n",
              "1  In the 35 years he has spent in this country, ...  ...                 0\n",
              "2  In the 35 years he has spent in this country, ...  ...                 0\n",
              "3       In the 35 years he has spent in this country  ...                 0\n",
              "4  In 2008, federal officials received a tip from...  ...                -1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKR2tlD0nz6N",
        "outputId": "0e36c21c-60ea-4290-8300-a08b549d01ff"
      },
      "source": [
        "!pip install stop-words\n",
        "from stop_words import get_stop_words\n",
        "stopwords = get_stop_words('en')\n",
        "from textblob import Word\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=7c06e5def0c0667811cae7a90e6ae8214978d301ed2a91aefec96dc6175fe569\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVebtzn3sWC3"
      },
      "source": [
        "Preprocessing function used to:\n",
        "\n",
        "\n",
        "*   Remove stop words\n",
        "*   Remove punctuation\n",
        "*   Split up sentence\n",
        "*   Clean data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB5pgtt-sjQ9"
      },
      "source": [
        "def utils_preprocess_text(txt, lst_regex=None, punkt=True, lower=True, lst_stopwords=None, stemm=False, lemm=True):\n",
        "    ## regex (in case, before processing)\n",
        "    if lst_regex is not None: \n",
        "        for regex in lst_regex:\n",
        "            txt = re.sub(regex, '', txt)\n",
        "    \n",
        "    ## clean \n",
        "    ### separate sentences with '. '\n",
        "    txt = re.sub(r'\\.(?=[^ \\W\\d])', '. ', str(txt))\n",
        "    ### remove punctuations and characters\n",
        "    txt = re.sub(r'[^\\w\\s]', '', txt) if punkt is True else txt\n",
        "    ### strip\n",
        "    txt = \" \".join([word.strip() for word in txt.split()])\n",
        "    ### lowercase\n",
        "    txt = txt.lower() if lower is True else txt\n",
        "            \n",
        "    ## Tokenize (convert from string to list)\n",
        "    lst_txt = txt.split()\n",
        "\n",
        "    ## remove Stopwords\n",
        "    if lst_stopwords is not None:\n",
        "        lst_txt = [word for word in lst_txt if word not in lst_stopwords]\n",
        "                \n",
        "    ## Stemming (remove -ing, -ly, ...)\n",
        "    if stemm is True:\n",
        "        ps = nltk.stem.porter.PorterStemmer()\n",
        "        lst_txt = [ps.stem(word) for word in lst_txt]\n",
        "                \n",
        "    ## Lemmatization (convert the word into root word)\n",
        "    if lemm is True:\n",
        "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "        lst_txt = [lem.lemmatize(word) for word in lst_txt]\n",
        "\n",
        "    ## remove leftover Stopwords\n",
        "    if lst_stopwords is not None:\n",
        "        lst_txt = [word for word in lst_txt if word not in lst_stopwords]\n",
        "            \n",
        "    ## back to string from list\n",
        "    txt = \" \".join(lst_txt)\n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRRyiVvcs6oU",
        "outputId": "3f2e1422-d031-494a-ec22-e148edd0d4a0"
      },
      "source": [
        "df['clean_text'] = df['Sentence'].apply( lambda x:utils_preprocess_text(x, stemm = False, lemm = True, lst_stopwords=stopwords))\n",
        "df['clean_text'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    petitioner jae lee moved united state south ko...\n",
              "1    35 year spent country never returned south kor...\n",
              "2     35 year spent country never returned south korea\n",
              "3                                35 year spent country\n",
              "4    2008 federal official received tip confidentia...\n",
              "Name: clean_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MhLePBrwiZ8"
      },
      "source": [
        "# Word embedding and model training\n",
        "Now that the text has been preprocessed, we will split the sentences up and change them into a vectorized format using word embedding.\n",
        "\n",
        "Then we will make the ML models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2GDl32R4Jva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3f3142-fb6e-4747-dce5-3d7d31e1344e"
      },
      "source": [
        "import gensim.downloader as api\n",
        "nlp = api.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rikPLnkf3EvI"
      },
      "source": [
        "# functions borrowed from Huyen's github\n",
        "# BOW based approaches\n",
        "nlp.init_sims(replace=True) # calling for using syn0norm\n",
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jh4AUNY3nxk",
        "outputId": "eebf235b-1dd0-45d5-ff78-b97f721b2afb"
      },
      "source": [
        "# functions borrowed from Huyen's github\n",
        "# Tokenize, and apply word vector averaging to tokenized text\n",
        "nltk.download('punkt')\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKDx8WMmw3F3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "X = df['clean_text']\n",
        "Y = df['Overall Sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6j36fdJ6k22",
        "outputId": "8b43e7fa-2b0b-46a5-b9f7-c29797610a98"
      },
      "source": [
        "X_train_tokenized = X_train.apply(lambda x: w2v_tokenize_text(x)).values\n",
        "X_test_tokenized = X_test.apply(lambda x: w2v_tokenize_text(x)).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(nlp,X_train_tokenized)\n",
        "X_test_word_average = word_averaging_list(nlp,X_test_tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  if sys.path[0] == '':\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Gmd_cz9Cb7",
        "outputId": "3de51a9b-1161-4d16-ad09-22397c618437"
      },
      "source": [
        "nlp[\"comics\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.05675178,  0.0182522 , -0.05054455,  0.10108911, -0.03310521,\n",
              "        0.00166265, -0.02187308,  0.05350038,  0.00591164, -0.03694777,\n",
              "        0.14010596,  0.01352288,  0.08394534,  0.01256224, -0.05290921,\n",
              "       -0.02216866,  0.05822969,  0.07685137, -0.00713092, -0.06295901,\n",
              "        0.00182891, -0.03354858,  0.07980719, -0.0614811 , -0.09222164,\n",
              "        0.00301124,  0.04817989,  0.10404493,  0.00245703, -0.12296219,\n",
              "       -0.06887065, -0.07980719, -0.04049476,  0.10108911,  0.033253  ,\n",
              "        0.06236784,  0.08276301,  0.02246425,  0.02911485,  0.14719993,\n",
              "       -0.00199518, -0.00208755,  0.09576863,  0.05379596, -0.05054455,\n",
              "        0.02468111, -0.00757429, -0.08571883,  0.01396626, -0.0399036 ,\n",
              "       -0.10227144, -0.06325459, -0.06916623,  0.09517746, -0.05231805,\n",
              "        0.01906505,  0.09517746,  0.04345058, -0.09695096, -0.08394534,\n",
              "        0.07744253, -0.04374616, -0.033253  , -0.04492849, -0.06000318,\n",
              "       -0.06236784, -0.14956458, -0.00702008, -0.01758714,  0.06532367,\n",
              "       -0.02261204,  0.05024897, -0.04611082, -0.0182522 , -0.06975739,\n",
              "        0.03354858, -0.0597076 ,  0.05261363, -0.01625702, -0.00089598,\n",
              "       -0.02689798, -0.01019759, -0.0149269 ,  0.02911485, -0.04167709,\n",
              "        0.01529638,  0.00360241,  0.07123531,  0.04492849, -0.05793411,\n",
              "        0.03753894, -0.07921603, -0.07744253, -0.0025494 , -0.01271003,\n",
              "       -0.02335099,  0.02778473, -0.01012369, -0.0514313 , -0.09813329,\n",
              "        0.0116755 ,  0.01980401, -0.01263614, -0.07507788,  0.07153089,\n",
              "       -0.03384416,  0.03783452, -0.10227144,  0.02394216, -0.04079034,\n",
              "       -0.00550522,  0.00447068,  0.01522248,  0.06502808,  0.03842568,\n",
              "       -0.01965621, -0.07330438,  0.03251404,  0.14838226, -0.07005298,\n",
              "       -0.01633092,  0.02793252,  0.02246425,  0.01876947,  0.00672449,\n",
              "       -0.06768832, -0.09517746,  0.08867466, -0.11586822, -0.05438712,\n",
              "       -0.03872127, -0.10700075, -0.03207067,  0.03753894, -0.02113413,\n",
              "        0.06029877,  0.01041927, -0.04049476,  0.06088993, -0.05704736,\n",
              "        0.08690117, -0.02763693, -0.00112691,  0.0762602 ,  0.05734294,\n",
              "       -0.02054296,  0.08867466, -0.00205984, -0.01677429,  0.01810441,\n",
              "        0.01056706, -0.01344899, -0.06000318,  0.08808349, -0.05941202,\n",
              "       -0.08808349, -0.05852527, -0.03310521, -0.05852527, -0.02024738,\n",
              "       -0.01559196, -0.02083854, -0.0564562 ,  0.1046361 ,  0.0413815 ,\n",
              "       -0.033253  ,  0.09695096,  0.0232032 , -0.02837589, -0.02734135,\n",
              "        0.13182965, -0.00140402,  0.04404175,  0.02216866, -0.03280962,\n",
              "       -0.01086265,  0.01714377, -0.15724972,  0.00653976,  0.05468271,\n",
              "        0.0780337 , -0.01596144, -0.05911644, -0.05438712,  0.0564562 ,\n",
              "       -0.04995339, -0.09813329,  0.03399195,  0.04611082,  0.07537346,\n",
              "        0.03724336,  0.03931243, -0.01736545,  0.01367068,  0.05675178,\n",
              "       -0.05822969,  0.05024897,  0.0464064 , -0.05616061, -0.02615902,\n",
              "       -0.07685137,  0.00432289,  0.0514313 ,  0.00823935,  0.01854778,\n",
              "       -0.00260482, -0.05084014, -0.1377413 , -0.15843205, -0.02246425,\n",
              "       -0.06443692,  0.08749232,  0.00306667,  0.00362088,  0.01596144,\n",
              "       -0.02364657,  0.01041927, -0.02438553, -0.00328835, -0.01980401,\n",
              "        0.02246425,  0.01204497,  0.02142971, -0.01396626, -0.0199518 ,\n",
              "        0.08808349, -0.0945863 ,  0.00441526, -0.00095602, -0.08926582,\n",
              "        0.01463132, -0.03000159, -0.09695096,  0.04404175,  0.01027148,\n",
              "        0.01396626,  0.07389554,  0.0116016 ,  0.12296219,  0.0399036 ,\n",
              "        0.00831325, -0.09281281,  0.01248835, -0.09754212, -0.09990678,\n",
              "       -0.02734135,  0.07744253,  0.08867466,  0.0215775 ,  0.02305541,\n",
              "        0.0065767 ,  0.06177668,  0.0165526 ,  0.02689798,  0.03783452,\n",
              "       -0.02024738, -0.03029717, -0.03000159, -0.03369637, -0.04433733,\n",
              "        0.02852368, -0.05616061,  0.02275983, -0.05024897, -0.0150008 ,\n",
              "        0.09990678,  0.07123531, -0.0399036 , -0.00772208, -0.09340397,\n",
              "       -0.04374616,  0.10581842, -0.03280962,  0.02941043,  0.10168027,\n",
              "        0.10640959,  0.03000159,  0.00210602, -0.02542007, -0.00613333,\n",
              "       -0.01788272,  0.03901685, -0.01374457,  0.06414133,  0.17380233,\n",
              "       -0.01795662, -0.0116755 ,  0.04877106, -0.02926264,  0.03118392,\n",
              "        0.03014938, -0.0199518 , -0.03591324,  0.03694777, -0.02527228,\n",
              "        0.00121928, -0.01374457,  0.0597076 ,  0.02793252, -0.07537346],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEfgnzQaWupA",
        "outputId": "89bada4b-0677-42b8-a063-37c2a9480a9e"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPoOSmDNyRDA"
      },
      "source": [
        "# Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_5or4PXY_Da"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import tree             # tree.DecisionTreeClassifier()\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm #clf = svm.SVC(decision_function_shape='ovo')\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEZm_Dc2yhM2"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzWlji_cymeu",
        "outputId": "d7fbec51-5451-4392-d4d2-2b9be4e54289"
      },
      "source": [
        "##### RANDOM FOREST ######\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Validate the model's performance using k-fold cross validation\n",
        "\n",
        "cv_rf = cross_validate (rf, X_train_word_average, y_train, cv = 10)\n",
        "print(\"Random Forest cross validation accuracy mean score: \\n\", cv_rf['test_score'].mean())\n",
        "\n",
        "rf.fit(X_train_word_average, y_train)\n",
        "y_pred_rf = rf.predict(X_test_word_average)\n",
        "print('accuracy %s' % accuracy_score(y_pred_rf, y_test))\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest cross validation accuracy mean score: \n",
            " 0.615625\n",
            "accuracy 0.6175\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.84      0.70       203\n",
            "           0       0.85      0.52      0.64        66\n",
            "           1       0.55      0.32      0.41       131\n",
            "\n",
            "    accuracy                           0.62       400\n",
            "   macro avg       0.67      0.56      0.58       400\n",
            "weighted avg       0.63      0.62      0.60       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdjM1jaSy6KW"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUP0mBZ-y9_A",
        "outputId": "e9ebc8a1-a8c4-4203-bfb0-fb75884bde92"
      },
      "source": [
        "# Fit the classifiers into the vectorized training set\n",
        "\n",
        "##### LOGISTIC REGRESSION ######\n",
        "logreg = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "\n",
        "# evaluate the accuracy score with cv\n",
        "cv_log = cross_validate (logreg, X_train_word_average, y_train, cv = 10)\n",
        "print(\"Logistic Regression CV accuracy mean score: \\n\", cv_log['test_score'].mean())\n",
        "# the accuracy mean score for SigmaLaw-ABSA maxes out around 75 iterations\n",
        "\n",
        "logreg.fit(X_train_word_average, y_train)\n",
        "y_pred_log = logreg.predict(X_test_word_average)\n",
        "print('accuracy on test set %s' % accuracy_score(y_pred_log, y_test))\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression CV accuracy mean score: \n",
            " 0.5893750000000001\n",
            "accuracy on test set 0.5925\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.77      0.68       203\n",
            "           0       0.65      0.45      0.54        66\n",
            "           1       0.53      0.39      0.45       131\n",
            "\n",
            "    accuracy                           0.59       400\n",
            "   macro avg       0.59      0.54      0.55       400\n",
            "weighted avg       0.59      0.59      0.58       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysbZTKI6y9Vt"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK2yfJ-UzVRV",
        "outputId": "642375da-04cd-4055-b874-2c395b9eb884"
      },
      "source": [
        "##### SVM ######\n",
        "svm = svm.SVC(decision_function_shape='ovo', probability=True)\n",
        "\n",
        "# Validate the model's performance using k-fold cross validation\n",
        "\n",
        "cv_svm = cross_validate (svm, X_train_word_average, y_train, cv = 10)\n",
        "print(\"SVM CV accuracy mean score: \\n\", cv_svm['test_score'].mean())\n",
        "\n",
        "svm.fit(X_train_word_average, y_train)\n",
        "y_pred_svm = svm.predict(X_test_word_average)\n",
        "print('accuracy on test set %s' % accuracy_score(y_pred_svm, y_test))\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM CV accuracy mean score: \n",
            " 0.6250000000000001\n",
            "accuracy on test set 0.6325\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.81      0.71       203\n",
            "           0       0.81      0.53      0.64        66\n",
            "           1       0.56      0.41      0.48       131\n",
            "\n",
            "    accuracy                           0.63       400\n",
            "   macro avg       0.67      0.58      0.61       400\n",
            "weighted avg       0.64      0.63      0.62       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cqIGrmGy-jE"
      },
      "source": [
        "**Decision Tree (X-G Boost)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmfyVh7EzUqk",
        "outputId": "155672bb-a13e-4b78-a395-a24573b24af6"
      },
      "source": [
        "##### Decision Tree ######\n",
        "tree = tree.DecisionTreeClassifier()\n",
        "\n",
        "# Validate the model's performance using k-fold cross validation\n",
        "\n",
        "cv_tree = cross_validate (tree, X_train_word_average, y_train, cv = 20)\n",
        "print(\"Decion Tree CV accuracy mean score: \\n\", cv_tree['test_score'].mean())\n",
        "\n",
        "tree.fit(X_train_word_average, y_train)\n",
        "y_pred_tree = tree.predict(X_test_word_average)\n",
        "print('accuracy on test set %s' % accuracy_score(y_pred_tree, y_test))\n",
        "print(classification_report(y_test, y_pred_tree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decion Tree CV accuracy mean score: \n",
            " 0.50625\n",
            "accuracy on test set 0.54\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.59      0.61      0.60       203\n",
            "           0       0.49      0.59      0.54        66\n",
            "           1       0.47      0.41      0.44       131\n",
            "\n",
            "    accuracy                           0.54       400\n",
            "   macro avg       0.52      0.54      0.53       400\n",
            "weighted avg       0.54      0.54      0.54       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZz4uIX7auhS"
      },
      "source": [
        "**Gradient Boost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHiqkMZpmI7L",
        "outputId": "243d09b2-8591-4729-e447-b85e2bc8d0e4"
      },
      "source": [
        "##### Gradient Boost ######\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Validate the model's performance using k-fold cross validation\n",
        "\n",
        "cv_gb = cross_validate (gb, X_train_word_average, y_train, cv = 10)\n",
        "print(\"Gradient Boost cross validation accuracy mean score: \\n\", cv_gb['test_score'].mean())\n",
        "\n",
        "gb.fit(X_train_word_average, y_train)\n",
        "y_pred_gb = gb.predict(X_test_word_average)\n",
        "print('accuracy %s' % accuracy_score(y_pred_gb, y_test))\n",
        "print(classification_report(y_test, y_pred_gb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Boost cross validation accuracy mean score: \n",
            " 0.6031249999999999\n",
            "accuracy 0.605\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.75      0.67       203\n",
            "           0       0.75      0.58      0.65        66\n",
            "           1       0.52      0.39      0.45       131\n",
            "\n",
            "    accuracy                           0.60       400\n",
            "   macro avg       0.63      0.57      0.59       400\n",
            "weighted avg       0.60      0.60      0.60       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}